{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Facial Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ceGkU7yQ-ax3",
        "ztky6L9E-lnP",
        "7Zu89RTzBMty",
        "k39FElpEMVju",
        "I4G1tEVgMnl0",
        "hLpNo_Wi78C3",
        "GL78P7u0I1Hp",
        "IyZvjJKTAMpx"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcfiDv03-cGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "from matplotlib.colors import ListedColormap\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTJESy7QA-5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data= pd.read_csv(\"drive/Colab Notebooks/emotion/fer2013.csv\")\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prR_SJxiBA8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZidMumXvBzpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(9,4))\n",
        "sns.countplot(x='emotion', data=data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qEMmC3ILEtp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['emotion'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JL5-9TQJMAbi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(9,4))\n",
        "sns.countplot(x='Usage', data=data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTzE2z-2Lpsh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['Usage'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OshjJPMx95JF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "image_size=(48,48)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRs4m6UvM7AO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pixels = data['pixels'].tolist() # Converting the relevant column element into a list for each row\n",
        "width, height = 48, 48\n",
        "faces = []\n",
        "\n",
        "for pixel_sequence in pixels:\n",
        "  face = [int(pixel) for pixel in pixel_sequence.split(' ')] # Splitting the string by space character as a list\n",
        "  face = np.asarray(face).reshape(width, height) #converting the list to numpy array in size of 48*48\n",
        "  face = cv2.resize(face.astype('uint8'),image_size) #resize the image to have 48 cols (width) and 48 rows (height)\n",
        "  faces.append(face.astype('float32')) #makes the list of each images of 48*48 and their pixels in numpyarray form\n",
        "  \n",
        "faces = np.asarray(faces) #converting the list into numpy array\n",
        "faces = np.expand_dims(faces, -1) #Expand the shape of an array -1=last dimension\n",
        "emotions = pd.get_dummies(df['emotion']).as_matrix() #doing the one hot encoding type on emotions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPsO_9sn77EB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(faces[0]) #Pixels after preprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2JENcOV_nXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(faces.shape)\n",
        "print(faces[0].ndim)\n",
        "print(type(faces))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeQMsBoR-Y4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(emotions[0]) #Emotion after preprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOO-ZRSf-hgt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(emotions.shape)\n",
        "print(emotions.ndim)\n",
        "print(type(emotions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2MJ1pnPJCyP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = faces.astype('float32')\n",
        "x = x / 255.0 #Dividing the pixels by 255 for normalization\n",
        "\n",
        "# Scaling the pixels value in range(-1,1)\n",
        "x = x - 0.5\n",
        "x = x * 2.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foWH2FX3JErZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(x[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_QhWHs_JGMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F5u4B83NKFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(x[0][0])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Euq0pES3Ufv_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(x.min(),x.max()) # we can observe that pixels are scale"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oIyb2zMU2sj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_samples, num_classes = emotions.shape\n",
        "\n",
        "num_samples = len(x)\n",
        "num_train_samples = int((1 - 0.2)*num_samples)\n",
        "\n",
        "# Traning data\n",
        "train_x = x[:num_train_samples]\n",
        "train_y = emotions[:num_train_samples]\n",
        "\n",
        "# Validation data\n",
        "val_x = x[num_train_samples:]\n",
        "val_y = emotions[num_train_samples:]\n",
        "\n",
        "train_data = (train_x, train_y)\n",
        "val_data = (val_x, val_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBtesONJWvDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Training Pixels',train_x.shape)\n",
        "print('Training labels',train_y.shape)\n",
        "\n",
        "print('Validation Pixels',val_x.shape)\n",
        "print('Validation labels',val_y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKpD2mbkD3V0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the libaray to built the model\n",
        "from keras.layers import Activation, Convolution2D, Dropout, Conv2D\n",
        "from keras.layers import AveragePooling2D, BatchNormalization\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import SeparableConv2D\n",
        "from keras import layers\n",
        "from keras.regularizers import l2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-h71E2cTFWOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_shape=(48, 48, 1)\n",
        "num_classes = 7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgnHh0urDr7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Convolution2D(filters=16, kernel_size=(7, 7), padding='same',\n",
        "                            name='image_array', input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(filters=16, kernel_size=(7, 7), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
        "model.add(Dropout(.5))\n",
        "\n",
        "model.add(Convolution2D(filters=32, kernel_size=(5, 5), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(filters=32, kernel_size=(5, 5), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
        "model.add(Dropout(.5))\n",
        "\n",
        "model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
        "model.add(Dropout(.5))\n",
        "\n",
        "model.add(Convolution2D(filters=128, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(filters=128, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
        "model.add(Dropout(.5))\n",
        "\n",
        "model.add(Convolution2D(filters=256, kernel_size=(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(filters=num_classes, kernel_size=(3, 3), padding='same'))\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Activation('softmax',name='predictions'))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1DSW_zoN1hg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS2a73LMMXsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parameters\n",
        "batch_size = 32 #Number of samples per gradient update\n",
        "num_epochs = 200 # Number of epochs to train the model.\n",
        "#input_shape = (64, 64, 1)\n",
        "verbose = 1 #per epohs  progress bar\n",
        "num_classes = 7 \n",
        "patience = 50\n",
        "base_path = 'drive/Colab Notebooks/emotion/simplecnn/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZGzV6XKVkmr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0vSiW0aVWoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data generator Generate batches of tensor image data with real-time data augmentation\n",
        "data_generator = ImageDataGenerator(\n",
        "                        featurewise_center=False,\n",
        "                        featurewise_std_normalization=False,\n",
        "                        rotation_range=10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeF9vG6oWMB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model parameters/compilation\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZP8riBlO4mS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datasets = ['fer2013']\n",
        "for dataset_name in datasets:\n",
        "    print('Training dataset:', dataset_name)\n",
        "\n",
        "    # callbacks\n",
        "    log_file_path = base_path + dataset_name + '_emotion_training.log'\n",
        "    csv_logger = CSVLogger(log_file_path, append=False)\n",
        "    early_stop = EarlyStopping('val_loss', patience=patience)\n",
        "    reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1,\n",
        "                                  patience=int(patience/4), verbose=1)\n",
        "    trained_models_path = base_path + dataset_name + 'simple_cnn'\n",
        "    model_names = trained_models_path + '.{epoch:02d}-{val_acc:.2f}.hdf5'\n",
        "    model_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1,\n",
        "                                                    save_best_only=True)\n",
        "    callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]\n",
        "\n",
        "    # loading dataset\n",
        "    train_faces, train_emotions = train_data\n",
        "    history=model.fit_generator(data_generator.flow(train_faces, train_emotions,\n",
        "                                            batch_size),\n",
        "                        epochs=num_epochs, verbose=1, callbacks=callbacks,\n",
        "                        validation_data=val_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vI4nPHW1WZ4r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(val_x, val_y, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1]*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzP_WR5DqZJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_dict=history.history\n",
        "history_dict.keys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzqA8Zq-UyqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(history_dict['acc']) + 1)\n",
        "\n",
        "plt.plot(epochs, train_loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEe3qvhv5ZA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_acc = history_dict['acc']\n",
        "val_acc = history_dict['val_acc']\n",
        "plt.plot(epochs, train_acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3lKbJ5khHVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "def load_image(image_path, grayscale=False, target_size=None):\n",
        "    pil_image = image.load_img(image_path, grayscale, target_size)\n",
        "    return image.img_to_array(pil_image)\n",
        "\n",
        "def load_detection_model(model_path):\n",
        "    detection_model = cv2.CascadeClassifier(model_path)\n",
        "    return detection_model\n",
        "\n",
        "def detect_faces(detection_model, gray_image_array):\n",
        "    return detection_model.detectMultiScale(gray_image_array, 1.3, 5)\n",
        "\n",
        "def draw_bounding_box(face_coordinates, image_array, color):\n",
        "    x, y, w, h = face_coordinates\n",
        "    cv2.rectangle(image_array, (x, y), (x + w, y + h), color, 2)\n",
        "\n",
        "def apply_offsets(face_coordinates, offsets):\n",
        "    x, y, width, height = face_coordinates\n",
        "    x_off, y_off = offsets\n",
        "    return (x - x_off, x + width + x_off, y - y_off, y + height + y_off)\n",
        "\n",
        "def draw_text(coordinates, image_array, text, color, x_offset=0, y_offset=0,\n",
        "                                                font_scale=0.5, thickness=2):\n",
        "    x, y = coordinates[:2]\n",
        "    cv2.putText(image_array, text, (x + x_offset, y + y_offset),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                font_scale, color, thickness, cv2.LINE_AA)\n",
        "\n",
        "def get_colors(num_classes):\n",
        "    colors = plt.cm.hsv(np.linspace(0, 1, num_classes)).tolist()\n",
        "    colors = np.asarray(colors) * 255\n",
        "    return colors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XhCPgxyhad0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from scipy.misc import imread, imresize\n",
        "\n",
        "\n",
        "def preprocess_input(x, v2=True):\n",
        "    x = x.astype('float32')\n",
        "    x = x / 255.0\n",
        "    if v2:\n",
        "        x = x - 0.5\n",
        "        x = x * 2.0\n",
        "    return x\n",
        "\n",
        "def _imread(image_name):\n",
        "        return imread(image_name)\n",
        "\n",
        "def _imresize(image_array, size):\n",
        "        return imresize(image_array, size)\n",
        "\n",
        "def to_categorical(integer_classes, num_classes=2):\n",
        "    integer_classes = np.asarray(integer_classes, dtype='int')\n",
        "    num_samples = integer_classes.shape[0]\n",
        "    categorical = np.zeros((num_samples, num_classes))\n",
        "    categorical[np.arange(num_samples), integer_classes] = 1\n",
        "    return categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgmGkZ30hiJb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_labels(dataset_name):\n",
        "    if dataset_name == 'fer2013':\n",
        "        return {0:'angry',1:'disgust',2:'fear',3:'happy',\n",
        "                4:'sad',5:'surprise',6:'neutral'}\n",
        "    elif dataset_name == 'imdb':\n",
        "        return {0:'woman', 1:'man'}\n",
        "    elif dataset_name == 'KDEF':\n",
        "        return {0:'AN', 1:'DI', 2:'AF', 3:'HA', 4:'SA', 5:'SU', 6:'NE'}\n",
        "    else:\n",
        "        raise Exception('Invalid dataset name')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mum5Ff5hjgM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "\n",
        "import cv2\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "\n",
        "'''from utils.datasets import get_labels\n",
        "from utils.inference import detect_faces\n",
        "from utils.inference import draw_text\n",
        "from utils.inference import draw_bounding_box\n",
        "from utils.inference import apply_offsets\n",
        "from utils.inference import load_detection_model\n",
        "from utils.inference import load_image\n",
        "from utils.preprocessor import preprocess_input'''\n",
        "\n",
        "# parameters for loading data and images\n",
        "image_path = sys.argv[1]\n",
        "detection_model_path = 'drive/Colab Notebooks/emotion/haarcascade_frontalface_alt2.xml'\n",
        "#emotion_model_path = 'trained_models/emotion_models/fer2013_mini_XCEPTION.102-0.66.hdf5'\n",
        "emotion_model_path = 'drive/Colab Notebooks/emotion/XCEPTION/fer2013_mini_XCEPTION.93-0.65.hdf5'\n",
        "#gender_model_path = 'trained_models/gender_models/simple_CNN.81-0.96.hdf5'\n",
        "emotion_labels = get_labels('fer2013')\n",
        "#gender_labels = get_labels('imdb')\n",
        "font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "\n",
        "# hyper-parameters for bounding boxes shape\n",
        "#gender_offsets = (30, 60)\n",
        "#gender_offsets = (10, 10)\n",
        "emotion_offsets = (20, 40)\n",
        "emotion_offsets = (0, 0)\n",
        "\n",
        "# loading models\n",
        "face_detection = load_detection_model(detection_model_path)\n",
        "emotion_classifier = load_model(emotion_model_path, compile=False)\n",
        "#gender_classifier = load_model(gender_model_path, compile=False)\n",
        "\n",
        "# getting input model shapes for inference\n",
        "emotion_target_size = emotion_classifier.input_shape[1:3]\n",
        "#gender_target_size = gender_classifier.input_shape[1:3]  \n",
        "\n",
        "# loading images\n",
        "rgb_image = load_image('2.jpg', grayscale=False)\n",
        "gray_image = load_image('1.jpg', grayscale=True)\n",
        "gray_image = np.squeeze(gray_image)\n",
        "gray_image = gray_image.astype('uint8')\n",
        "\n",
        "\n",
        "\n",
        "faces = detect_faces(face_detection, gray_image)\n",
        "#faces = detect_faces(face_detection)\n",
        "for face_coordinates in faces:\n",
        "    #x1, x2, y1, y2 = apply_offsets(face_coordinates, gender_offsets)\n",
        "    #rgb_face = rgb_image[y1:y2, x1:x2]\n",
        "\n",
        "    x1, x2, y1, y2 = apply_offsets(face_coordinates, emotion_offsets)\n",
        "    gray_face = gray_image[y1:y2, x1:x2]\n",
        "\n",
        "    try:\n",
        "        #rgb_face = cv2.resize(rgb_face, (gender_target_size))\n",
        "        gray_face = cv2.resize(gray_face, (emotion_target_size))\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "    #rgb_face = preprocess_input(rgb_face, False)\n",
        "    #rgb_face = np.expand_dims(rgb_face, 0)\n",
        "    #gender_prediction = gender_classifier.predict(rgb_face)\n",
        "    #gender_label_arg = np.argmax(gender_prediction)\n",
        "    #gender_text = gender_labels[gender_label_arg]\n",
        "\n",
        "    gray_face = preprocess_input(gray_face, True)\n",
        "    gray_face = np.expand_dims(gray_face, 0)\n",
        "    gray_face = np.expand_dims(gray_face, -1)\n",
        "    emotion_label_arg = np.argmax(emotion_classifier.predict(gray_face))\n",
        "    emotion_text = emotion_labels[emotion_label_arg]\n",
        "\n",
        "    if emotion_text == emotion_labels[0]:\n",
        "        color = (0, 0, 255)\n",
        "    else:\n",
        "        color = (255, 0, 0)\n",
        "\n",
        "    draw_bounding_box(face_coordinates, rgb_image, color)\n",
        "    #draw_text(face_coordinates, rgb_image, gender_text, color, 0, -20, 1, 2)\n",
        "    draw_text(face_coordinates, rgb_image, emotion_text, color, -20, -20, 0.7, 2)\n",
        "\n",
        "bgr_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2BGR)\n",
        "cv2.imwrite('abc.jpg', bgr_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ16t7K8iRCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image\n",
        "Image('2.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0bIR4cGmFqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image('1.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twAK_mEjmojS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image('abc.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R44SNhMUomOk",
        "colab_type": "text"
      },
      "source": [
        "# 2) Xception Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSBcupl4osoG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_shape=(48,48,1)\n",
        "num_classes=7\n",
        "l2_regularization=0.01\n",
        "regularization = l2(l2_regularization)\n",
        "\n",
        "\n",
        "img_input = Input(input_shape)\n",
        "x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization,\n",
        "                                              use_bias=False)(img_input)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization,\n",
        "                                              use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "\n",
        "residual = Conv2D(16, (1, 1), strides=(2, 2),padding='same', use_bias=False)(x)\n",
        "residual = BatchNormalization()(residual)\n",
        "\n",
        "x = SeparableConv2D(16, (3, 3), padding='same',\n",
        "                        kernel_regularizer=regularization,\n",
        "                        use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = SeparableConv2D(16, (3, 3), padding='same',\n",
        "                        kernel_regularizer=regularization,\n",
        "                        use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "x = layers.add([x, residual])\n",
        "\n",
        "residual = Conv2D(32, (1, 1), strides=(2, 2),\n",
        "                      padding='same', use_bias=False)(x)\n",
        "residual = BatchNormalization()(residual)\n",
        "\n",
        "x = SeparableConv2D(32, (3, 3), padding='same',\n",
        "                        kernel_regularizer=regularization,\n",
        "                        use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = SeparableConv2D(32, (3, 3), padding='same',\n",
        "                        kernel_regularizer=regularization,\n",
        "                        use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "x = layers.add([x, residual])\n",
        "\n",
        "\n",
        "residual = Conv2D(64, (1, 1), strides=(2, 2),\n",
        "                      padding='same', use_bias=False)(x)\n",
        "residual = BatchNormalization()(residual)\n",
        "\n",
        "x = SeparableConv2D(64, (3, 3), padding='same',\n",
        "                        kernel_regularizer=regularization,\n",
        "                        use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = SeparableConv2D(64, (3, 3), padding='same',\n",
        "                        kernel_regularizer=regularization,\n",
        "                        use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "x = layers.add([x, residual])\n",
        "\n",
        "\n",
        "residual = Conv2D(128, (1, 1), strides=(2, 2),\n",
        "                      padding='same', use_bias=False)(x)\n",
        "residual = BatchNormalization()(residual)\n",
        "\n",
        "x = SeparableConv2D(128, (3, 3), padding='same',\n",
        "                        kernel_regularizer=regularization,\n",
        "                        use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = SeparableConv2D(128, (3, 3), padding='same',\n",
        "                        kernel_regularizer=regularization,\n",
        "                        use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "x = layers.add([x, residual])\n",
        "\n",
        "x = Conv2D(num_classes, (3, 3), padding='same')(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "output = Activation('softmax',name='predictions')(x)\n",
        "\n",
        "model = Model(img_input, output)\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKLFB1D8xZx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "486oY_TOzNhk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4xZKzkdxjQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 100\n",
        "num_epochs = 200\n",
        "input_shape = (64, 64, 1)\n",
        "validation_split = .2\n",
        "verbose = 1\n",
        "num_classes = 7\n",
        "patience = 50\n",
        "base_path = 'drive/Colab Notebooks/emotion/Xception2/'\n",
        "data_generator = ImageDataGenerator(\n",
        "                        featurewise_center=False,\n",
        "                        featurewise_std_normalization=False,\n",
        "                        rotation_range=10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "datasets = ['fer2013']\n",
        "for dataset_name in datasets:\n",
        "    print('Training dataset:', dataset_name)\n",
        "\n",
        "    # callbacks\n",
        "    log_file_path = base_path + dataset_name + '_emotion_training.log'\n",
        "    csv_logger = CSVLogger(log_file_path, append=False)\n",
        "    early_stop = EarlyStopping('val_loss', patience=patience)\n",
        "    reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1,\n",
        "                                  patience=int(patience/4), verbose=1)\n",
        "    trained_models_path = base_path + dataset_name + '_mini_XCEPTION'\n",
        "    model_names = trained_models_path + '.{epoch:02d}-{val_acc:.2f}.hdf5'\n",
        "    model_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1,\n",
        "                                                    save_best_only=True)\n",
        "    callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]\n",
        "\n",
        "    # loading dataset\n",
        "    train_faces, train_emotions = train_data\n",
        "    history=model.fit_generator(data_generator.flow(train_faces, train_emotions,\n",
        "                                            batch_size),\n",
        "                        steps_per_epoch=len(train_faces) / batch_size,\n",
        "                        epochs=num_epochs, verbose=1, callbacks=callbacks,\n",
        "                        validation_data=val_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByNuF43gzG97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(val_x, val_y, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1]*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgXW9mXK0Tu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_dict=history.history\n",
        "history_dict.keys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhWG4zPv03U2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(history_dict['acc']) + 1)\n",
        "\n",
        "plt.plot(epochs, train_loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fS2T2tBE1DhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_acc = history_dict['acc']\n",
        "val_acc = history_dict['val_acc']\n",
        "plt.plot(epochs, train_acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYDnHedNfK3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image\n",
        "Image('2.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hV0g_UxzgS5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image('1.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHEBktIVgZgZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image('abc.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}